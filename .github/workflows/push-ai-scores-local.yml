name: Push AI Scores (local joblib)
on:
  workflow_dispatch:
  schedule:
    - cron: "*/5 9-20 * * 1-5"  # every 5 minutes during US premarket + RTH (UTC)

jobs:
  push:
    runs-on: ubuntu-latest
    env:
      APP_URL: ${{ vars.APP_URL }}  # e.g. https://your-app.vercel.app
    steps:
      - name: Check APP_URL
        run: |
          if [ -z "${APP_URL}" ]; then
            echo "::error ::APP_URL repo variable not set. Go to Settings → Secrets and variables → Actions → Variables and add APP_URL=https://<your-vercel-url>";
            exit 1;
          fi
          echo "Using APP_URL=${APP_URL}"

      - name: Check out repo
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install Python deps
        run: |
          python -m pip install --upgrade pip
          # Adjust versions if your model needs a specific sklearn/xgboost/lightgbm
          pip install numpy pandas joblib scikit-learn requests

      - name: Fetch /api/stocks
        run: |
          curl -fsS "${APP_URL}/api/stocks" -H "accept: application/json" -o stocks.json
          head -c 400 stocks.json || true
          echo

      - name: Build scores with local model & POST
        env:
          SCORES_API_KEY: ${{ secrets.SCORES_API_KEY }}
        run: |
          python - <<'PY'
          import os, json, time, math
          import numpy as np
          import pandas as pd
          import joblib
          import requests

          APP_URL = os.environ["APP_URL"].rstrip("/")
          KEY = os.environ["SCORES_API_KEY"]

          # --- locate model file in repo root ---
          # try both names just in case
          MODEL_CANDIDATES = ["printedai_score.joblib", "ai_score.joblib", "model.joblib"]
          model_path = None
          for p in MODEL_CANDIDATES:
            if os.path.exists(p):
              model_path = p
              break
          if not model_path:
            raise FileNotFoundError(f"No joblib model found; tried: {MODEL_CANDIDATES}")

          print(f"Loading model: {model_path}")
          model = joblib.load(model_path)

          # --- load stocks list pulled in previous step ---
          with open("stocks.json","r") as f:
            raw = json.load(f)
          rows = raw.get("data") or raw.get("items") or raw.get("stocks") or []

          def to_float(x):
            if x is None: return None
            try:
              s = str(x).strip()
              if s.endswith("%"): s = s[:-1]
              return float(s)
            except:
              return None

          # Build a simple feature set the same way the dashboard expects
          # If your trained model expects different columns, adjust FEATURE_COLS below to match.
          recs = []
          for r in rows:
            t = str(r.get("symbol") or r.get("ticker") or "").upper()
            if not t: 
              continue
            gap = to_float(r.get("gap") or r.get("gap_pct") or r.get("gapPct"))
            chg = to_float(r.get("change") or r.get("change_pct") or r.get("changePercent"))
            if gap is None and chg is not None:
              gap = chg  # proxy if finviz only gives change%
            recs.append({
              "ticker": t,
              "gap_pct": gap,
              "rvol": to_float(r.get("relativeVolume") or r.get("relVolume") or r.get("rvol")),
              "float_m": to_float(r.get("floatM") or r.get("float_m")) 
                         or (to_float(r.get("float_shares"))/1e6 if r.get("float_shares") is not None else None),
              "price": to_float(r.get("price")),
              "rsi14m": to_float(r.get("rsi14m") or r.get("rsi")),
              "volume": to_float(r.get("volume")),
            })

          df = pd.DataFrame.from_records(recs)

          # Choose the feature columns your model expects.
          # If your model used a different schema, edit this list to match the training.
          FEATURE_COLS = ["gap_pct","rvol","float_m","price","rsi14m"]
          for c in FEATURE_COLS:
            if c not in df.columns: df[c] = np.nan

          X = df[FEATURE_COLS].astype(float).fillna(0.0)

          # Inference that works across sklearn models (classifier or regressor)
          def as_prob(pred):
            # clamp to [0,1]
            try:
              return max(0.0, min(1.0, float(pred)))
            except:
              return 0.0

          if hasattr(model, "predict_proba"):
            probs = model.predict_proba(X)
            if probs.ndim == 2 and probs.shape[1] >= 2:
              scores = probs[:, 1]
            else:
              scores = probs.ravel()
          else:
            raw_pred = model.predict(X)
            # min-max to [0,1] as a fallback if regressor
            mn, mx = float(np.min(raw_pred)), float(np.max(raw_pred))
            if math.isclose(mx, mn):
              scores = np.zeros_like(raw_pred, dtype=float)
            else:
              scores = (raw_pred - mn) / (mx - mn)

          scores = np.array([as_prob(s) for s in scores])

          out = []
          for i, t in enumerate(df["ticker"].tolist()):
            out.append({
              "ticker": t,
              "score": float(scores[i]),
              "gap_pct": to_float(df.at[i,"gap_pct"]),
              "rvol": to_float(df.at[i,"rvol"]),
              "rsi14m": to_float(df.at[i,"rsi14m"]),
              "price": to_float(df.at[i,"price"]),
              "volume": to_float(df.at[i,"volume"]),
            })

          payload = {
            "generatedAt": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
            "scores": out
          }

          print("Posting", len(out), "scores to /api/scores")
          r = requests.post(
            f"{APP_URL}/api/scores",
            headers={"content-type": "application/json", "x-api-key": KEY},
            data=json.dumps(payload),
            timeout=45
          )
          r.raise_for_status()
          print("OK:", r.status_code)
          PY
